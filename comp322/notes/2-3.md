# Processes cont.
February 3, 2022

## PCB Storage

### Contents of the PCB
The PCB as a data structure contains lots of info, including the state of the CPU, state of the process itself, memory location, scheduling and accounting info, open files and other resources, and parents + children. Only some of these fields are dynamic - that is, some data about a process may not be changed over the lifecycle of the process (such as a parent).

PCBs can be implemented as "heterogeneous" records of different types: integers, characters, and pointers may all be contained in a PCB. Thus, the common implementation is as a general object (or "struct" in the C language):
- CPU_state, scheduling, and accounting information may all be stored as a set of integers
- process state may be stored as either integers or characters
- memory address will be stored as a pointer, whereas a parent field may be stored as either a pointer or array index to the parent PCB
- open files and acquired resources, as well as child processes, may be a linked list of pointers

### PCB Organization
The OS must allocate and free space for PCBs as processes are created and terminated. PCBs are often stored as either an array of structures, or an array of pointers. The first implementation is simple to implement, as each structure index is marked as free or reserved and dynamic memory management is not necessary; the drawback is a lot of wasted space for structures which may or may not be used. An array of pointers makes for a smaller storage footprint, and can be made much larger than an array of structures. However, care must be taken to manage memory and collect garbage dynamically to avoid memory leaks.

Linked lists require dynamic memory management to collect garbage and manage pointers in each node. Linux pioneered an approach to avoid a linked list in the children field. Instead of a parent PCB containing a list of children, a first child is designated and each child points to its next older and younger siblings. This avoids having to update an entire list of children when a sibling is destroyed, avoiding dynamic memory management completely.

### PCB Management
Lists are maintained by the OS to track processes in various ways. A **waiting list** can be used to contain all processes waiting for a given resource to become available. A **ready list** can track all processes which are currently able to be moved into a running state. The ready list orders processes by their priority. This is simply implemented by using a linked list, but a structure such as a priority queue may be used as well. Multiple processes with the same priority value may be listed together in a linked list.

## PCB operations
A **process creation hierarchy** is a sort of family tree for all processes. It maintains the parent-child relationships and changes each time a process is created or destroyed. A "root" process (level 0) is created as the highest ancestor of all OS processes (level 1), and user processes (level 2) can be spawned from the OS (usually from a single OS process - in Unix, this process is called "init"). Users can start application processes (level 3), which may in turn create their own helper processes (level 4).

When a process is destroyed, the OS must handle the levels of relationships below the destroyed process. Some OSs may attach children of a deleted process to another OS process, such as Unix does with init when user processes are terminated. Other OSs may simply destroy all child processes when the parent is destroyed.

### Creation/Destruction
The OS will execute a creation function to handle allocation and initialization of processes when a currently running process calls for a new child. The function allocates a structure for the new PCB, fills initial values, and links the PCB to other data structures currently present in the system via sibling and parent pointers. Initial values for memory address, CPU state, scheduling info, and accounting info are supplied as parameters to the create function. The new process is then inserted into the ready list and the scheduler can execute the new process according to its priority.

A process can be terminated by its parent, as well as when all work is completed by a process or it encounters a fatal error. A destroy function is executed by the OS when it is called in one of those scenarios, and handles the garbage collection procedure by freeing space occupied by the PCB and removing any references to the PCB from the system. Depending on the OS in use, the destroy process may or may not be called recursively on children of the process to be destroyed - regardless, children of the destroyed process need to be handled in order to prevent memory leakage. The function then removes the destroyed process from any lists and calls the scheduler to select a process to run.

## Resources
Resources are represented in memory similar to processes, through the creation of a **resource control block (RCB).** Specific implementation details vary among OS varieties, but typically include a description of the resource, it's state, and the waiting list associated with the resource. A resource can be hardware-based (such as a keyboard, printer, or disk) or software-based (such as timers, database locks, and buffers). An RCB can be implemented in a variety of ways, depending on how its fields are represented and if the number of resources is fixed. Arrays can be used to represent the collection of RCBs when resources are finite or fixed, or using a linked list when the number of resources may change. RCBs themselves can be represented using either arrays, if all fields can be represented using the same data type, or as structure objects (just like PCBs).

### Request/Release
A resource is allocated to a requesting process if it has access to the resource, and is able to utilize it. The resource is free when it is not in use and is ready to be allocated. When a currently running process needs a resource, a request function is called. If the resource is free and able to be allocated, the state of the RCB is changed to "allocated" and a pointer to the resource is added to the resources list of the PCB. If it is not free, the requesting process is moved from the ready list to the resource's waiting list, and the scheduler must pick another process to run. Because a process can be blocked from running from a single resource, multiple blocked resources can create delays in runtime, as the process can only make new requests when it is running. A non-blocking call checks if a resource is available before making the request call, and can allow a process to continue running if a resource request would block continued operation.

Allocated resources are re-assigned when the process calls a release function. If the RCB has a waiting list, the resource is allocated to the next process on the list and it's PCB state is updated from "blocked" to "ready." The scheduler must then be called to decide on which process to execute on the ready list. If the waiting list is empty, the RCB is again marked as free. If a resource has multiple assignable units, then a release may trigger "ready" state transitions for more than one process.

## Scheduling
The scheduler handles the work assigned to the CPU and makes sure that it is always occupied with a process. A schedule function is called every time a process or resource operation function is ending. When a process is created or destroyed, or a resource is requested or released, the scheduler will find the highest priority process on the ready list and initiate a context switch. The switch is completed if the priority of the currently running function is lower than the highest priority process on the ready list (as is possible when a process is created or a resource is freed via a release call or destroyed function), or if the state of the currently running process changes to "blocked" (such as after a request is made on an unavailable resource)

## Threads
A brief introduction to threading concepts can be explained using the above methods. When an application implemented as a single process is blocked by an unavailable resource, the execution of the application stops entirely. If an application is built using modular processes, then the application can continue execution when its individual processes get blocked. However, creating a PCB for each of potentially many processes is inefficient. An even better solution would be executing multiple processes concurrently, with processes running in parallel rather than awaiting a blocking resource request for a context switch. A thread is an instance of a queue of tasks. A portion of an application may execute in a thread without the cost of maintaining multiple PCBs. Multiple CPUs, or a single CPU with multithreading capability, can execute processes or process tasks on multiple threads at the same time. Information for each thread is maintained in a **thread control block (TCB),** which contains the runtime information of its assigned PCB as well as the execution stack. Therefore, each TCB replicates a minimal amount of information, while utilizing the same code, global data, and resources in a single PCB.

Threads can be created at the user level by applications, encapsulating thread management within the process, Threads may also be managed by the kernel, and threads can be accessed through kernel function calls. Context switching between threads can therefore be initiated by either a process or the kernel, depending on how the thread is implemented. 

Modern OSs use a combination of **user-level threads (ULT)** as well as **kernel-level threads (KLT).** An application can create any number of ULTs, which are then mapped onto a limited number of KLTs based on priority and needed resources. ULTs are much faster to manage than KLTs, can be created in larger quantities, and applications which implement their own threads are more portable between different systems. ULTs in a process are still recognized by the kernel as a single execution unit, however, and a blocked thread can halt an entire application and will not take advantage of multiple CPUs when available. 