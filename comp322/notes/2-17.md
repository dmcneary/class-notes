# Concurrrency
February 17, 2022

The idea of concurrency describes doing multiple things (or processes) at once. When multiple CPUs are available, processes may execute in parallel. On a single CPU, concurrency may be achieved by time-sharing.

## Process Interactions
If two processes are run in sequence, data which is shared between them is not at risk of inconsistency. However, when concurrent processes access the same data area, it must be protected from simultaneous change. This area is called a **critical section (CS).**

A software-based solution to the CS problem has a number of requirements:
- **Mutual exclusion**: only one process may be executing the code in the CS
- **Lockout**: the CS is not barred to access by any process which is not currently trying to execute code which it contains
- **Starvation**: while other processes are waiting to access the CS, access cannot be repeatedly prevented by a greedy process
- **Deadlock**: If multiple processes try to access the CS at the same time, they must not block each other forever.

In addition to competition between processes, applications often utilize mutliple processes working together to accomplish a task. Thus, these processes must be allowed to communicate effectively to exchange data between each other.

## Semaphores
A semphore is essentially a gate, or a flag. It allows one process into a CS at a time, based on the state of the semaphore, and removes responsibility for cooperation or competition from individual processes.

The semaphore <code>s</code> is typically implemented as a non-negative integer which can be accessed only by two operations, traditionally called <code>p(s)</code> and <code>v(s)</code>. Based on Dijkstra's Dutch translations describing incrementing and decrementing actions, <code>v(s)</code> will increment the semaphore and <code>p(s)</code> will decrement the semaphore if it is greater than zero. Implementation of these operations must guarantee that simultaneous calls execute sequentially, and a queue of processes waiting to call <code>p(s)</code> will be unblocked one at a time (this can be a random selection, but is usually performed using FIFO).

### The bounded-buffer problem
A classic synchronization problem, this example uses a circular buffer in which a producer and a consumer access slots. The producer makes data slot by slot, which the consumer deletes in the same order. When the buffer is full, the producer must stop and wait for the consumer to free a slot; likewise, if the buffer is empty, the consumer must wait for the producer to fill a slot. Semaphores solve this issue very elegantly by creating counters for filling and emptying slots, <code>f</code> and <code>e</code>. When the producer makes data, it calls <code>p(e)</code> on the empty counter and waits for it to be greater than zero. Upon success of the call, it will place data into the buffer and increment the full counter with <code>v(f)</code>. The consumer follows a similar process, waiting for the full counter to be greater than zero before calling <code>p(f)</code>. It then removes the data from the buffer and calls <code>v(e)</code> to increment.